{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e063267-844f-4f80-986c-ff7cd0205ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60a12e-81ab-4c6a-a3fa-4f3cada23e79",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f392f965-5a5d-40be-9bbe-9365d488a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNoisyData(num_points=50):\n",
    "    x = np.linspace(1, 4*math.pi, num_points)\n",
    "    y = np.sin(x*0.5)\n",
    "    nmu, sigma = 0, 0.3\n",
    "    noise = nmu + sigma * np.random.randn(num_points)\n",
    "    t = y + noise\n",
    "    np.savez('data.npz', x=x, y=y, t=t, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829877c1-9e9c-4da6-a62f-3541a1dd83dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(x=None, y=None, pred1 = None, label1 = None, sigma = False, pred2 = None, label2 = None, title = None, file_name = None, num_points = 50):\n",
    "    if not os.path.exists(f'results{num_points}'):\n",
    "        os.makedirs(f'results{num_points}')\n",
    "    np.load(f'data{num_points}.npz')\n",
    "    x = np.load(f'data{num_points}.npz')['x']\n",
    "    y = np.load(f'data{num_points}.npz')['y']\n",
    "    t = np.load(f'data{num_points}.npz')['t']\n",
    "    sigma = np.load(f'data{num_points}.npz')['sigma']\n",
    "    nmu, sigma = 0, 0.3\n",
    "    noise = nmu + sigma * np.random.randn(num_points)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y, 'g', label = \"Ground Truth\")\n",
    "    ax.plot(x, pred1, 'r', label = label1)\n",
    "    if pred2 is not None:\n",
    "        ax.plot(x, pred2, \"y\", label = label2)\n",
    "        ax.fill_between(x, y-sigma, y+sigma, color='r', alpha=0.2)\n",
    "    ax.scatter(x, t, label='Noisy Data Points')\n",
    "    if pred2 is None:\n",
    "        ax.fill_between(x, pred1-sigma, pred1+sigma, color='r', alpha=0.2)\n",
    "        lines = [[(i, j), (i, line)] for i, j, line in zip(x, pred1, t)]    \n",
    "        lc = mc.LineCollection(lines, colors='red', linewidths=1, zorder=1)\n",
    "        ax.add_collection(lc)\n",
    "    ax.set_xlabel('X Values')\n",
    "    ax.set_ylabel('Y Values, Predictions, Noisy Data')\n",
    "    ax.set_title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'results{num_points}/{file_name}.png')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a518cb5-caed-45c8-9fab-01bdd7a98135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML():\n",
    "    def __init__(self, degree = None):\n",
    "        self.degree = degree\n",
    "    def fit(self, x, y):\n",
    "        x = PolynomialFeatures(degree = self.degree).fit_transform(x.reshape(-1,1))\n",
    "        intermediate = (x.T)@x\n",
    "        weights = np.linalg.solve(intermediate, (x.T)@y)\n",
    "        return weights\n",
    "    def predict(self, x, weights):\n",
    "        x = PolynomialFeatures(degree = self.degree).fit_transform(x.reshape(-1,1))\n",
    "        predictions = np.dot(x, weights)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b044b57-31ab-428f-9a11-3e2d6d66a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAP():\n",
    "    def __init__(self, alpha=0.005, beta=11.1, lnlambda = None, customReguralization = False, degree = None):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.lnlambda = lnlambda\n",
    "        self.customReguralization = customReguralization\n",
    "        self.degree = degree\n",
    "    def fit(self, x, y):\n",
    "        if self.customReguralization:\n",
    "            lnlambda = self.lnlambda\n",
    "        else:\n",
    "            lnlambda = np.log(self.alpha/self.beta)\n",
    "        x = PolynomialFeatures(degree = self.degree).fit_transform(x.reshape(-1,1))\n",
    "        intermediate = ((x.T)@x) + np.exp(lnlambda)*np.eye(x.shape[1], x.shape[1])\n",
    "        weights = np.linalg.solve(intermediate, (x.T)@y)\n",
    "        return weights\n",
    "    def predict(self, x, weights):\n",
    "        x = PolynomialFeatures(degree = self.degree).fit_transform(x.reshape(-1,1))\n",
    "        predictions = np.dot(x, weights)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5572e7b-69d6-4e20-ab66-35351ad7aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(num_points = 50, calcRMSE = False, rmse_degree = 9):\n",
    "    np.load(f'data{num_points}.npz')\n",
    "    x = np.load(f'data{num_points}.npz')['x']\n",
    "    y = np.load(f'data{num_points}.npz')['y']\n",
    "    t = np.load(f'data{num_points}.npz')['t']\n",
    "    sigma = np.load(f'data{num_points}.npz')['sigma']\n",
    "\n",
    "    ml_weights_dict, map_weights_dict = {}, {}\n",
    "\n",
    "    for i in [0,1,3,6,9]:\n",
    "        ML_Model = ML(degree = i)\n",
    "        ml_weights = ML_Model.fit(x, t)\n",
    "        ml_predictions = ML_Model.predict(x, ml_weights)\n",
    "        ml_weights_dict[f\"ML:{i}\"] = pad_weights(ml_weights)\n",
    "        plot_results(x, y, ml_predictions, title = f\"ML Model Degree {i}\", file_name = f\"ml_{i}\", label1 = \"ML Model Prediction\", num_points = num_points)\n",
    "    print(f\"Number of Points: {num_points}\")\n",
    "    print(pd.DataFrame(ml_weights_dict))\n",
    "\n",
    "    for i in [0,1,3,6,9]:\n",
    "        MAP_Model = MAP(degree = i, customReguralization = False)\n",
    "        map_weights = MAP_Model.fit(x, t)\n",
    "        map_predictions = MAP_Model.predict(x, map_weights)\n",
    "        map_weights_dict[f\"MAP:{i}\"] = pad_weights(map_weights)\n",
    "        plot_results(x, y, map_predictions, title = f\"MAP Model Degree {i}\", file_name = f\"map_{i}\", label1 = \"MAP Model Prediction\", num_points = num_points)\n",
    "    print(f\"Number of Points: {num_points}\")    \n",
    "    print(pd.DataFrame(map_weights_dict))\n",
    "\n",
    "    for i in [3,9,15,20,30,40,50]:\n",
    "        ML_Model = ML(degree = i)\n",
    "        MAP_Model = MAP(degree = i)\n",
    "        ml_weights = ML_Model.fit(x, t)\n",
    "        map_weights = MAP_Model.fit(x, t)\n",
    "        ml_predictions = ML_Model.predict(x, ml_weights)\n",
    "        map_predictions = MAP_Model.predict(x, map_weights)\n",
    "        plot_results(x, y, pred1 = ml_predictions, label1 = f\"ML Model Degree: {i}\", \\\n",
    "                        title = f\"ML vs MAP Predictions Degree: {i}\", \\\n",
    "                        pred2 = map_predictions, label2 = f\"MAP Model Degree: {i}\", \\\n",
    "                        file_name = f\"ml_vs_map{i}\", num_points = num_points)\n",
    "\n",
    "    if calcRMSE:\n",
    "        rmse_arr = []\n",
    "        for lnlambda in range(-40, -20):\n",
    "            inputs = np.load(\"data50.npz\")[\"x\"]\n",
    "            targets = np.load(\"data50.npz\")[\"t\"]\n",
    "            rmseModel = MAP(degree = rmse_degree, customReguralization = True, lnlambda = lnlambda)\n",
    "            weights = rmseModel.fit(inputs, targets)\n",
    "            predictions = rmseModel.predict(inputs, weights)\n",
    "            rmse_error = rmse(predictions, targets)\n",
    "            rmse_arr.append(rmse_error)\n",
    "        plt.plot(range(-40,-20), rmse_arr)\n",
    "        # plt.ylim([0, 1])\n",
    "        plt.xlabel(r\"ln$\\lambda$\")\n",
    "        plt.ylabel(r\"$E_{RMS}$\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    for lnlambda in [-18, -15, -13]:\n",
    "        CustomModel = MAP(degree = 3, customReguralization = True, lnlambda = lnlambda)\n",
    "        custom_weights = CustomModel.fit(x, t)\n",
    "        custom_predictions = CustomModel.predict(x, custom_weights)\n",
    "        plot_results(x, y, custom_predictions, title = r\"Custom Model Degree 3, ln$\\lambda$ = \" + str(lnlambda), file_name = f\"lnlambda{lnlambda}\", label1 = r\"$ln\\lambda$ = \"+str(lnlambda)+\" Model\", num_points = num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd552b8-1ea4-42ff-bac1-c7b54517aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_points in [20,50,500]:\n",
    "    generateNoisyData(num_points = num_points)\n",
    "    plot_with_shadded_bar(num_points = num_points)\n",
    "    linear_regression(num_points = num_points, calcRMSE = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f64b7-07dc-420f-89be-b8de236c8189",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2cb49-70d3-4223-810f-bfa6945e20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_desc_bounds(classifier, feats, labels, idxA, idxB):\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    ys = np.sort(np.unique(labels))\n",
    "    y_ind = np.searchsorted(ys, labels)\n",
    "    fig, ax = plt.subplots()\n",
    "    x0, x1 = feats[:, 0], feats[:, 1]\n",
    "    all_feats = np.concatenate((x0, x1))\n",
    "    pad = np.percentile(all_feats, 60)\n",
    "    x_min, x_max = x0.min() - pad, x0.max() + pad\n",
    "    y_min, y_max = x1.min() - pad, x1.max() + pad\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "    preds = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    preds = preds.reshape(xx.shape)\n",
    "    lut = np.sort(np.unique(labels)) \n",
    "    ind = np.searchsorted(lut,preds)\n",
    "    markers = [\"o\", \"v\", \"P\", \"X\", \"s\", \"p\", \"h\", \"d\"]\n",
    "    ax.contourf(xx, yy, preds, cmap=plt.cm.Pastel1, alpha=0.8)\n",
    "    for i in range(len(lut)):\n",
    "        ax.scatter(x0[y_ind == i], x1[y_ind == i], color=plt.cm.jet(i/len(lut)), s=50, edgecolors='k', marker=markers[i])\n",
    "    ax.set_xlabel(f'Feature {idxA}')\n",
    "    ax.set_ylabel(f'Feature {idxB}')\n",
    "    ax.set_title('Decision Boundary')\n",
    "    handles = []\n",
    "    markers = [\"o\", \"v\", \"P\", \"X\", \"s\", \"p\", \"h\", \"d\"]\n",
    "    handles = [plt.plot([],[],color=plt.cm.jet(i/len(lut)), ls=\"\", marker=markers[i])[0] for i in range(len(lut))]\n",
    "    labels = [f'Class {i}' for i in lut]\n",
    "    ax.legend(handles, labels, loc='upper right')\n",
    "    plt.savefig(f'results/example_boundary.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b7a23f-0781-4efa-bfa2-8f9235ff0bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset='taiji', verbose=False, subject_index=3):\n",
    "    if dataset == 'taiji':\n",
    "        labels = np.loadtxt(\"../P1/data/taiji/taiji_labels.csv\", delimiter=\",\", dtype=int)\n",
    "        person_idxs = np.loadtxt(\"../P1/data/taiji/taiji_person_idx.csv\", delimiter=\",\", dtype=int)\n",
    "        feats = np.loadtxt(\"../P1/data/taiji/taiji_quat.csv\", delimiter=\",\", dtype=float)\n",
    "        labels[labels == 4] = 2\n",
    "        labels[labels == 8] = 6\n",
    "        feature_mask = np.var(feats, axis=1) > 0\n",
    "        train_mask = person_idxs != subject_index\n",
    "        train_feats = feats[feature_mask, :][:, train_mask].T\n",
    "        train_labels = labels[train_mask].astype(int)\n",
    "        test_feats = feats[feature_mask, :][:, ~train_mask].T\n",
    "        test_labels = labels[~train_mask].astype(int)\n",
    "    if verbose:\n",
    "        print(f'{dataset} Dataset Loaded')\n",
    "        print(f'\\t# of Classes: {len(np.unique(train_labels))}')\n",
    "        print(f'\\t# of Features: {train_feats.shape[1]}')\n",
    "        print(f'\\t# of Training Samples: {train_feats.shape[0]}')\n",
    "        print('\\t# per Class in Train Dataset:')\n",
    "        for cls in np.unique(train_labels):\n",
    "            print (f'\\t\\tClass {cls}: {np.sum(train_labels == cls)}')\n",
    "        print(f'\\t# of Testing Samples: {test_feats.shape[0]}')\n",
    "        print('\\t# per Class in Test Dataset:')\n",
    "        for clas in np.unique(test_labels):\n",
    "            print(f'\\t\\tClass {clas}: {np.sum(test_labels == clas)}')\n",
    "    return train_feats, train_labels, test_feats, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33327c4-8490-4866-8a1a-e5762c815d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mats(dataset, **kwargs):\n",
    "    train_labels = kwargs['train_labels']\n",
    "    pred_train_labels = kwargs['pred_train_labels']\n",
    "    test_labels = kwargs['test_labels']\n",
    "    pred_test_labels = kwargs['pred_test_labels']\n",
    "    train_confusion = confusion_matrix(train_labels, pred_train_labels)\n",
    "    test_confusion = confusion_matrix(test_labels, pred_test_labels)\n",
    "    fig, ax = plt.subplots()\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=train_confusion, display_labels=np.unique(train_labels))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical')\n",
    "    ax.set_title('Training Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{dataset}_train_confusion.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=test_confusion, display_labels=np.unique(test_labels))\n",
    "    disp.plot(ax=ax, xticks_rotation='vertical')\n",
    "    ax.set_title('Testing Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/{dataset}_test_confusion.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c62035-5332-4a46-a378-71a1746792dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_decision_boundary(dataset='taiji', indices=[0, 6]):\n",
    "    train_feats, train_labels, test_feats, test_labels = load_dataset(dataset=dataset)\n",
    "    dc_train_feats = train_feats[:, indices]\n",
    "    dc_test_feats = test_feats[:, indices]\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(dc_train_feats, train_labels)\n",
    "    viz_desc_bounds(clf, dc_test_feats, test_labels, indices[0], indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e6394-18b6-4568-860a-221a4f1a8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_classification(dataset='taiji'):\n",
    "    train_feats, train_labels, test_feats, test_labels = load_dataset(dataset=dataset)\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(train_feats, train_labels)\n",
    "    pred_train_labels = clf.predict(train_feats)\n",
    "    pred_test_labels = clf.predict(test_feats)\n",
    "    plot_conf_mats(dataset, train_labels=train_labels, pred_train_labels=pred_train_labels, test_labels=test_labels, pred_test_labels=pred_test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
